{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Connecting with the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c759d27a-94f3-4141-945d-065f2095bffd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Intro\n",
    "* Input: the prompt we send to the LLM.\n",
    "* Output: the response from the LLM.\n",
    "* We can switch LLMs and use several different LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981f91b-686d-401c-a872-65487f93b46e",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* LLMs.\n",
    "* Prompts and Prompt Templates.\n",
    "* Types of prompts: Zero Shot and Few Shot(s) Prompt.\n",
    "* Serialization: Saving and Loading Prompts.\n",
    "* Parsing Outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332b6e9-8164-4859-879c-f021a4dfd69d",
   "metadata": {},
   "source": [
    "## LangChain divides LLMs in two types\n",
    "1. LLM Model: text-completion model.\n",
    "2. Chat Model: converses with a sequence of messages and can have a particular role defined (system prompt). This type has become the most used in LangChain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42a3ca-fc4d-4b91-b3bc-a7304ec4d5f8",
   "metadata": {},
   "source": [
    "## See the differences\n",
    "* Even when sometimes the LangChain documentation can be confusing about it, the fact is that text-completion models and Chat models are both LLMs.\n",
    "* But, as you can see in this [playground](https://platform.openai.com/playground/chat?models=gpt-4o), they have some significant differences. See that the chat models in LangChain have system messages, human messages (called \"user messages\" by OpenAI) and AI messages (called \"Assitant Messages\" by OpenAI).\n",
    "* Since the launch of chatGPT, the Chat Model is the most popular LLM type and is used in most LLM apps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f9501-fa9e-4830-95e2-537dff951cf1",
   "metadata": {},
   "source": [
    "## List of LLMs that can work with LangChain\n",
    "* See the list [here](https://python.langchain.com/v0.1/docs/integrations/llms/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### Recommended: create new virtualenv\n",
    "* mkdir your_project_name\n",
    "* cd your_project_name\n",
    "* pyenv virtualenv 3.11.4 your_venv_name\n",
    "* pyenv activate your_venv_name\n",
    "* pip install jupyterlab\n",
    "* jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f9e964-c5c2-4a13-b9ed-c449362ae7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "#### .env File\n",
    "Remember to include:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **connectWithLLMs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1d17b-6d15-423b-b554-26d6d977ca27",
   "metadata": {},
   "source": [
    "## LLM Model\n",
    "* The trend before the launch of chatGPT-4.\n",
    "* See LangChain documentation about LLM Models [here](https://python.langchain.com/v0.1/docs/modules/model_io/llms/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92628f2-62e8-436c-92d4-e849de7744ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeaf300-5cb6-4df8-bcb9-1fe3c82e4b22",
   "metadata": {},
   "source": [
    "#### Invoke: all the text of the reponse is printed at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ade5fa-b487-4f32-bda7-0f9c41b096b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmModel.invoke(\n",
    "    \"Tell me one fun fact about the Kennedy family.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a33285ef-4bb5-4fd6-9894-790c07a5468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe Kennedy family has a long-standing tradition of playing touch football on Thanksgiving Day. This tradition was started by President John F. Kennedy and his brothers during their childhood and has continued through the generations, with the family still playing touch football every year.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa71043-4707-44b4-8d1f-8540d5d139b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Kennedy family has a long-standing tradition of playing touch football on Thanksgiving Day. This tradition was started by President John F. Kennedy and his brothers during their childhood and has continued through the generations, with the family still playing touch football every year.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c29ae-d60a-44c7-925c-20084c0b941e",
   "metadata": {},
   "source": [
    "#### Streaming: printing one chunk of text at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158aa111-9167-444c-9b10-90b095eac390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One fun fact about the Kennedy family is that they have a long-standing tradition of playing touch football on Thanksgiving Day. This tradition started with President John F. Kennedy and his brothers and has been carried on by subsequent generations of the Kennedy family."
     ]
    }
   ],
   "source": [
    "for chunk in llmModel.stream(\n",
    "    \"Tell me one fun fact about the Kennedy family.\"\n",
    "):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98101f10-6349-4f98-9fb7-a1400166cedc",
   "metadata": {},
   "source": [
    "#### Temperature: more or less creativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac12473a-1ffd-4a22-852a-92e1e6374914",
   "metadata": {},
   "outputs": [],
   "source": [
    "creativeLlmModel = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325b9b2a-c61d-4264-81bf-71090f9b0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llmModel.invoke(\n",
    "    \"Write a short 5 line poem about JFK\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "679c1220-13ed-4251-ba4b-f8f1ba350f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A president of hope and grace,\n",
      "His words still echo in this place.\n",
      "From Massachusetts to the White House halls,\n",
      "JFK's legacy forever calls.\n",
      "Gone too soon, but never forgotten,\n",
      "JFK, forever an American icon.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31346a0c-ee9c-4a80-8e8a-85ef682df7c3",
   "metadata": {},
   "source": [
    "## Chat Model\n",
    "* The general trend after the launch of chatGPT-4.\n",
    "    * Frequently known as \"Chatbot\". \n",
    "    * Conversation between Human and AI.\n",
    "    * Can have a system prompt defining the tone or the role of the AI. \n",
    "* See LangChain documentation about Chat Models [here](https://python.langchain.com/v0.1/docs/modules/model_io/chat/).\n",
    "* By default we will work with ChatOpenAI. See [here](https://python.langchain.com/v0.1/docs/integrations/chat/openai/) the LangChain documentation page about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b14d27c3-0b1b-4b11-a883-8da2734f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eaa967e-067f-4574-8cbc-b1e5b7956fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are an historian expert in the Kennedy family.\"),\n",
    "    (\"human\", \"Tell me one curious thing about JFK.\"),\n",
    "]\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f567f5a-c4ea-4234-84e6-422bf6104589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One curious thing about John F. Kennedy (JFK) is that he won a Pulitzer Prize in 1957 for his book \"Profiles in Courage.\" This book highlighted acts of political courage by eight United States Senators throughout the country\\'s history. However, there has been some controversy and debate surrounding the extent of JFK\\'s actual involvement in writing the book, with some suggesting that he had significant help from his speechwriter and adviser, Ted Sorensen. Nonetheless, the Pulitzer Prize was awarded to JFK for the book, adding to his legacy as a writer and politician.', response_metadata={'token_usage': {'completion_tokens': 115, 'prompt_tokens': 29, 'total_tokens': 144}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4df00bf9-a180-4880-9171-7233ef163ef4-0', usage_metadata={'input_tokens': 29, 'output_tokens': 115, 'total_tokens': 144})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19a6abd4-a072-47ea-ae60-7959def9b602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One curious thing about John F. Kennedy (JFK) is that he won a Pulitzer Prize in 1957 for his book \"Profiles in Courage.\" This book highlighted acts of political courage by eight United States Senators throughout the country\\'s history. However, there has been some controversy and debate surrounding the extent of JFK\\'s actual involvement in writing the book, with some suggesting that he had significant help from his speechwriter and adviser, Ted Sorensen. Nonetheless, the Pulitzer Prize was awarded to JFK for the book, adding to his legacy as a writer and politician.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47927ac1-13bc-40eb-9917-9d39418f0f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 115,\n",
       "  'prompt_tokens': 29,\n",
       "  'total_tokens': 144},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7847143f-3179-423e-b499-a6e494967741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'AIMessage',\n",
       " 'description': 'Message from an AI.',\n",
       " 'type': 'object',\n",
       " 'properties': {'content': {'title': 'Content',\n",
       "   'anyOf': [{'type': 'string'},\n",
       "    {'type': 'array',\n",
       "     'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "  'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "  'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "  'type': {'title': 'Type', 'default': 'ai', 'enum': ['ai'], 'type': 'string'},\n",
       "  'name': {'title': 'Name', 'type': 'string'},\n",
       "  'id': {'title': 'Id', 'type': 'string'},\n",
       "  'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "  'tool_calls': {'title': 'Tool Calls',\n",
       "   'default': [],\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "  'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "   'default': [],\n",
       "   'type': 'array',\n",
       "   'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "  'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       " 'required': ['content'],\n",
       " 'definitions': {'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54631efb-dbe2-4bd7-b588-324f19a28b2c",
   "metadata": {},
   "source": [
    "#### Before the previous one, the old way (but still very popular) of doing this was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a20ba943-ce6b-45e2-9dbb-351c48421069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b879a5f4-2250-4a70-b065-7796c4fe9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an historian expert on the Kennedy Family.\"),\n",
    "    HumanMessage(content=\"How many children had Joseph P. Kennedy?\"),\n",
    "]\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78f9b26b-e7e1-4613-8e3e-0c81f8b54da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Joseph P. Kennedy, Sr. and his wife Rose Kennedy had nine children: Joseph Jr., John F. Kennedy, Rosemary, Kathleen, Eunice, Patricia, Robert F. Kennedy, Jean, and Edward \"Ted\" Kennedy.', response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 30, 'total_tokens': 79}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2468164a-6a85-4614-903d-a25dffe243b6-0', usage_metadata={'input_tokens': 30, 'output_tokens': 49, 'total_tokens': 79})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41204f4-0cec-4039-a18d-2a25b9dd5efd",
   "metadata": {},
   "source": [
    "#### Streaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83d9f1d0-bba8-4885-9ac1-01fc273732b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy and his wife Rose Kennedy had nine children. Their children were Joseph Jr., John F. (Jack), Rosemary, Kathleen, Eunice, Patricia, Robert F. (Bobby), Jean, and Edward M. (Ted)."
     ]
    }
   ],
   "source": [
    "for chunk in chatModel.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd276b9-494a-47c2-8455-2ff33fc4f221",
   "metadata": {},
   "source": [
    "#### Another old way, similar results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bc0210b-27e0-41ed-8ad8-ff1c75c9bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are expert {profession} in {topic}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chatModel\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"profession\": \"Historian\",\n",
    "        \"topic\": \"Kennedy Family\",\n",
    "        \"input\": \"Tell me one fun fact about JFK.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc436d53-b372-43eb-ac00-ee39c9fa491a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One fun fact about JFK is that he was the first U.S. president to hold a press conference that was broadcast live on television. This event took place on January 25, 1961, and it marked a new era in which the American public could directly see and hear their president addressing important issues.', response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 28, 'total_tokens': 90}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bb3735b6-44b8-4741-ab0f-d16c4785493f-0', usage_metadata={'input_tokens': 28, 'output_tokens': 62, 'total_tokens': 90})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f91601-8594-41d3-9316-d51791fc54e8",
   "metadata": {},
   "source": [
    "## Prompts\n",
    "* See the LangChain documentation about prompts [here](https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/).\n",
    "* Input into LLMs.\n",
    "* Prompt templates: easier to use prompts with variables. A prompt template may include:\n",
    "    * instructions,\n",
    "    * few-shot examples,\n",
    "    * and specific context and questions appropriate for a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5383c7e-7e62-46d0-8bef-17ff45a88495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nOne of the most mysterious and curious stories about the Kennedy family revolves around the death of JFK's brother, Robert F. Kennedy. After JFK's assassination in 1963, Robert became the leading candidate for the Democratic Party's presidential nomination in 1968.\\n\\nHowever, on June 5, 1968, just moments after winning the California primary, Robert was shot in the head by a man named Sirhan Sirhan. He died the next day, leaving the Kennedy family and the entire nation in shock.\\n\\nWhat makes this story even more intriguing is the fact that Sirhan Sirhan has maintained his innocence and claimed that he has no memory of the shooting. In fact, numerous conspiracy theories have emerged over the years, suggesting that there was a larger plot behind Robert's assassination.\\n\\nOne theory suggests that Sirhan Sirhan was a victim of mind control and was programmed to shoot Robert Kennedy by a mysterious organization. Another theory implicates the CIA and the Mafia in a plot to eliminate Robert, who was seen as a threat to their interests.\\n\\nDespite numerous investigations and trials, the truth behind Robert Kennedy's assassination remains a mystery, adding to the enduring fascination and curiosity surrounding the Kennedy family.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} story about {topic}.\"\n",
    ")\n",
    "\n",
    "llmModelPrompt = prompt_template.format(\n",
    "    adjective=\"curious\", \n",
    "    topic=\"the Kennedy family\"\n",
    ")\n",
    "\n",
    "llmModel.invoke(llmModelPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beb7dbcd-524c-4acc-9b65-0b209a170ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an {profession} expert on {topic}.\"),\n",
    "        (\"human\", \"Hello, Mr. {profession}, can you please answer a question?\"),\n",
    "        (\"ai\", \"Sure!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession=\"Historian\",\n",
    "    topic=\"The Kennedy family\",\n",
    "    user_input=\"How many grandchildren had Joseph P. Kennedy?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7585be48-9a19-43ab-a275-8ef6a04246a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Joseph P. Kennedy, Sr., the patriarch of the Kennedy family, had a total of 28 grandchildren. These grandchildren are the descendants of his nine children, including President John F. Kennedy, Senator Robert F. Kennedy, and Ambassador Jean Kennedy Smith.', response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 55, 'total_tokens': 106}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c705253b-8dae-40df-b61f-375437732042-0', usage_metadata={'input_tokens': 55, 'output_tokens': 51, 'total_tokens': 106})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1373ca0b-342f-4ac6-a697-5e2ad30bfa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Joseph P. Kennedy, Sr., the patriarch of the Kennedy family, had a total of 28 grandchildren. These grandchildren are the descendants of his nine children, including President John F. Kennedy, Senator Robert F. Kennedy, and Ambassador Jean Kennedy Smith.' response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 55, 'total_tokens': 106}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-c705253b-8dae-40df-b61f-375437732042-0' usage_metadata={'input_tokens': 55, 'output_tokens': 51, 'total_tokens': 106}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f6a5e25-e177-4d7a-ba29-6834a6a8152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy, Sr., the patriarch of the Kennedy family, had a total of 28 grandchildren. These grandchildren are the descendants of his nine children, including President John F. Kennedy, Senator Robert F. Kennedy, and Ambassador Jean Kennedy Smith.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d770b4-80c5-49a6-a925-de3a800d19f2",
   "metadata": {},
   "source": [
    "#### Old way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6dafd17-47a2-4169-992e-76ffb9702d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are an Historian expert on the Kennedy family.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    user_input=\"Name the children and grandchildren of Joseph P. Kennedy?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a4d5a5a-c3a3-48be-8b31-40b0881faa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joseph P. Kennedy and his wife Rose Fitzgerald Kennedy had nine children:\n",
      "\n",
      "1. Joseph P. Kennedy Jr.\n",
      "2. John F. Kennedy\n",
      "3. Rosemary Kennedy\n",
      "4. Kathleen Kennedy\n",
      "5. Eunice Kennedy\n",
      "6. Patricia Kennedy\n",
      "7. Robert F. Kennedy\n",
      "8. Jean Kennedy\n",
      "9. Edward M. Kennedy\n",
      "\n",
      "Joseph P. Kennedy's grandchildren include the children of his nine children, such as Caroline Kennedy (John F. Kennedy's daughter), Maria Shriver (Eunice Kennedy's daughter), and Robert F. Kennedy Jr. (Robert F. Kennedy's son), among others.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b510dd0-33b7-4737-aef2-c52a1e8bbf41",
   "metadata": {},
   "source": [
    "#### What is the full potential of ChatPromptTemplate?\n",
    "* Check the [corresponding page](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) in the LangChain API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f8be09-99fc-491e-babb-0b8ad5bc74c2",
   "metadata": {},
   "source": [
    "## Few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "301ae08a-e223-4239-8eca-8468ceb1e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b882accd-e3e7-4e8a-9d85-55ebaa945837",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"¡adiós!\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b973d828-0f47-4c43-98ab-e3db306d41e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¿Quién fue JFK?', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 52, 'total_tokens': 58}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-58c5f017-a750-46a7-95c9-d4ee1745798c-0', usage_metadata={'input_tokens': 52, 'output_tokens': 6, 'total_tokens': 58})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an English-Spanish translator.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chatModel\n",
    "\n",
    "chain.invoke({\"input\": \"Who was JFK?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721c4a4-56d6-48e2-b9db-0de0309c492a",
   "metadata": {},
   "source": [
    "## Parsing Outputs\n",
    "* See the corresponding LangChain Documentation page [here](https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/).\n",
    "* Language models output text. But many times you may want to get more structured information than just text back. This is where output parsers come in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "177b19be-ea45-4ecb-a4dc-914da7958de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "json_chain = json_prompt | llmModel | json_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4ed2-f174-4177-b38d-b03397e4f2a7",
   "metadata": {},
   "source": [
    "#### The previous prompt template includes the parser instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "047f7986-5502-4205-9a7a-e7e7e26f51a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecb755d4-4a0f-486a-99dd-ea1873eb7c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The 3 biggest countries are Russia, Canada, and China.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_chain.invoke({\"question\": \"List the 3 biggest countries\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1181d87-13df-4abf-9910-0b44618642de",
   "metadata": {},
   "source": [
    "#### Optionally, you can use Pydantic to define a custom output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdcf2860-9b94-46f9-94f8-81ce173b8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "873de824-c105-4e36-b4a7-d4bb498efc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7006219-e78f-4f1f-8d8a-559679f84845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two tired!'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up a parser\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# Inject parser instructions into the prompt template.\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Create a chain with the prompt and the parser\n",
    "chain = prompt | chatModel | parser\n",
    "\n",
    "chain.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c93f3-a1ff-41de-af09-bc67729ad271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
