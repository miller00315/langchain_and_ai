{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465c003a-29cf-4cfe-a0c6-d36c04ae2b37",
   "metadata": {},
   "source": [
    "# Intro to LCEL in 06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a73fbf-e241-499d-a235-32a87b46ee7c",
   "metadata": {},
   "source": [
    "## Intro\n",
    "* LCEL has become the backbone of the newest versions of LangChain.\n",
    "* Traditional chains are still supported, but treated as \"Legacy\" and have less functionality than the new LCEL chains.\n",
    "* Many students struggle with LCEL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46ff75-72ab-4391-904f-459bae77fc7a",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* In the previous LCEL section of the bootcamp:\n",
    "    * chains.\n",
    "    * output parsers.\n",
    "    * arguments.\n",
    "    * openai functions.\n",
    "    * rag applications.\t\t\n",
    "\n",
    "* Main goals of LCEL.\n",
    "* Legacy chain vs LCEL chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dadf119-5eb4-479b-b121-a3a31ae41074",
   "metadata": {},
   "source": [
    "## Main goals of LCEL\n",
    "* Make it easy to build complex chains.\n",
    "* Support functionality such as streaming, parallelism and logging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### Recommended: create new virtualenv\n",
    "* mkdir your_project_name\n",
    "* cd your_project_name\n",
    "* pyenv virtualenv 3.11.4 your_venv_name\n",
    "* pyenv activate your_venv_name\n",
    "* pip install jupyterlab\n",
    "* jupyter lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "57f9e964-c5c2-4a13-b9ed-c449362ae7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "#### .env File\n",
    "Remember to include:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **lcelZeroToMaster**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1998155-91de-4cbc-bc88-8d77beefb51b",
   "metadata": {},
   "source": [
    "* NOTE: Since right now is the best LLM in the market, we will use OpenAI by default. You will see how to connect with other Open Source LLMs like Llama3 or Mistral in a next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae8595e-5c07-4b02-8a79-db55fd357527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b5d23-5d09-4c88-b32f-3299795cd91b",
   "metadata": {},
   "source": [
    "## Legacy Chain vs. LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a34484-0981-4edc-8ba2-7c8521d28c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e25b31-f858-4016-aaff-7325b5595d63",
   "metadata": {},
   "source": [
    "#### Legacy Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181ba6bd-cf77-43e0-8eb9-0c8e274b3051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliocolomer/.pyenv/versions/3.11.4/envs/venv061224-p1/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Maradona once scored a goal with his hand during the 1986 FIFA World Cup quarter-final match against England. This controversial goal, known as the \"Hand of God,\" went undetected by the referees and helped Argentina win the game 2-1.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a curious fact about {soccer_player}\")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "traditional_chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "traditional_chain.predict(soccer_player=\"Maradona\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb069f5-558d-4494-830d-958aa4f78ef3",
   "metadata": {},
   "source": [
    "#### New LCEL Chain\n",
    "* The \"pipe\" operator `|` is the main element of the LCEL chains.\n",
    "* The order (left to right) of the elements in a LCEL chain matters.\n",
    "* An LCEL Chain is a Sequence of Runnables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246e32f8-4380-41d2-b33a-04ff4085569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ronaldo is known for his incredible work ethic and dedication to training. He reportedly spends several hours each day practicing and working out to maintain his high level of fitness and skill on the field.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1026d5-2e99-4fd4-af2a-ac2c6d2eeeac",
   "metadata": {},
   "source": [
    "* All the components of the chain are Runnables.\n",
    "* When we write chain.invoke() we are using invoke with all the componentes of the chain in an orderly manner:\n",
    "    * First, we apply .invoke() to the prompt.\n",
    "    * Then, with the previous output, we apply .invoke() to the model.\n",
    "    * And finally, with the previous output, we apply .invoke() to the output parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc942a2e-b9d3-4f5f-a612-f212cacc8bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
